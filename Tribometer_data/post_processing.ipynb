{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tribo as tb\n",
    "import numpy as np\n",
    "import os \n",
    "import re\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter as sgf\n",
    "\n",
    "def split_string(s):\n",
    "    return re.split('[-_]', s)\n",
    "\n",
    "\"\"\"Self.outliers \n",
    "\n",
    "if not file.outlier:\n",
    "\n",
    "\"\"\"\n",
    "outlier_tests = {'OA_Project_Tests_CoF':['20wt_C20A2wtOA_10N_100mms_Test11', \\\n",
    "                       '20wt_C20A_20N_100mms_Test2', \\\n",
    "                        '20wt_C20A_20N_20mms_Test8', \\\n",
    "                        '20wt_C20A2wtOA_20N_20mms_Test7', \\\n",
    "\t\t\t\t\t\t'100-TOCN_10N_20mms_Test7', \\\n",
    "\t\t\t\t\t\t'100-TOCN_20N_20mms_Test10'], \\\n",
    "            \n",
    "            'PAO_IL_ZDDP_CoF': ['0_OA0_20N_100mms_test2', \\\n",
    "                                '1_IL_20N_100mms_Test5', \\\n",
    "                                '1_IL_20N_20mms_Test2', \\\n",
    "                                '1_IL_20N_20mms_Test1']}\n",
    "\n",
    "class Tribo_file:\n",
    "\tdef __init__(self,file_folder, file_name, outlier=False):\n",
    "\t\tself.file_name = file_name\n",
    "\t\tself.file_folder = file_folder\n",
    "\t\tself.percent,self.name,self.force,self.speed,self.test = split_string(self.file_name)\n",
    "\t\tself.outlier=outlier\n",
    "\t\t\n",
    "\t\tself.load_data()\n",
    "\n",
    "\tdef load_data(self):\n",
    "\t\tself.data,self.xpos,self.Fx,self.Fz = tb.get_data(self.file_folder+\"\\\\\"+self.file_name,\"all\")\n",
    "\t\t\n",
    "\n",
    "\tdef process_data(self,cutoff=0.1):\n",
    "\n",
    "\t\tself.xpos_peaks, self.xpos_valleys = tb.find_x_segments(self.xpos)\n",
    "\n",
    "\t\tsegments=tb.segment_data(self.xpos, self.xpos_peaks, self.xpos_valleys,self.Fx,self.Fz)\n",
    "\n",
    "\t\tself.upward_sections, self.forward_friction, self.downward_sections, self.backward_friction=segments\n",
    "\n",
    "\t\tself.CoF_array = tb.calculate_CoF(self.upward_sections, self.forward_friction, self.downward_sections, self.backward_friction,cutoff)\n",
    "\n",
    "\t\tself.CoF_avg=np.average(self.CoF_array)\n",
    "\t\tself.CoF_std=np.std(self.CoF_array, ddof=1)\n",
    "\n",
    "\t\tpad_length = 3000 - len(self.CoF_array)\n",
    "\t\tif pad_length > 0:\n",
    "\t\t\tpadded_array = np.pad(file_n.CoF_array, (0, pad_length), 'constant', constant_values=self.CoF_avg)\n",
    "\t\telse:\n",
    "\t\t\tpadded_array = file_n.CoF_array\n",
    "\n",
    "\t\tself.CoF_array=padded_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t\n",
    "\n",
    "folder = 'OA_Project_Tests_CoF'\n",
    "\n",
    "files_in_folder = os.listdir(folder)\n",
    "print(f\" Found {len(files_in_folder)} files in {folder}\")\n",
    "\n",
    "Tribo_files = []\n",
    "complete_CoF_df = pd.DataFrame()\n",
    "sg_smoothing = pd.DataFrame()\n",
    "\n",
    "test_list = [] # testing \n",
    "\n",
    "for file_name in files_in_folder:\n",
    "\tif file_name in outlier_tests[folder]:\n",
    "\t\ttest_list.append(file_name)\n",
    "\t\tfile_n=Tribo_file(folder, file_name, outlier=True)\n",
    "\telse:\n",
    "\t\tfile_n=Tribo_file(folder, file_name)\n",
    "\tfile_n.process_data(0.2)\n",
    "\tTribo_files.append(file_n)\n",
    "\t# print(f\"Processed {file_name} with CoF {file_n.CoF_array.shape} and % {file_n.percent} \")\n",
    "\tcomplete_CoF_df[file_name]=file_n.CoF_array\n",
    "\n",
    "for column in complete_CoF_df.columns:\n",
    "\tsg_smoothing[column]=sgf(complete_CoF_df[column], 100, 2)\n",
    "\n",
    "speeds=[]\n",
    "names=[]\n",
    "# outliers = []\n",
    "\n",
    "for file in Tribo_files:\n",
    "\tif file.speed not in speeds:\n",
    "\t\tspeeds.append(file.speed)\n",
    "\n",
    "\tif file.name not in names:\n",
    "\t\tnames.append(file.name)\n",
    "\t# if file.outlier:\n",
    "\t# \toutliers.append(file.file_name)\n",
    "\n",
    "# print(f\" Procesing {speeds}\")\n",
    "\n",
    "speed_sheets=[]\n",
    "\n",
    "# for speed in speeds:\n",
    "# \tfiles_with_speed = [file for file in Tribo_files if file.speed == speed]\n",
    "\n",
    "\t\n",
    "# \trows=[]\n",
    "# \tii=0\n",
    "# \tfor file in files_with_speed:\n",
    "# \t\tdata_to_append = [ file.name,  file.CoF_avg,  file.CoF_std,file.percent,file.force,file.test]\n",
    "# \t\trows.append(data_to_append)\n",
    "\n",
    "# \tdf = pd.DataFrame(rows,columns=['Name','CoF_avg','CoF_std','Percent','Force','Test'])\n",
    "\n",
    "\n",
    "# \tspeed_sheets.append(df)\n",
    "\n",
    "rows=[]\n",
    "count1 = 0 # Testing\n",
    "for file in Tribo_files:\n",
    "\tif file.outlier:\n",
    "\t\tcount1 += 1\n",
    "\t\tcontinue\n",
    "\tif file.speed == '10mms':\n",
    "\t\tcontinue\n",
    "\tdata_to_append = [ file.name,  file.CoF_avg,  file.CoF_std,file.speed, file.percent, file.force,file.test]\n",
    "\trows.append(data_to_append)\n",
    "\n",
    "print('Outliers num: ', count1)\n",
    "print('Outlier Files found: ', test_list)\n",
    "\t\n",
    "\n",
    "df = pd.DataFrame(rows,columns=['Name','CoF_avg','CoF_std','Speed','Percent','Force','Test'])\n",
    "\n",
    "print(\"This is the complete df\\n\",df)\n",
    "for speed in speeds:\n",
    "\tspeed_sheet=df[df['Speed']==speed]\n",
    "\tprint(\"speed sheet\\n\",speed_sheet)\n",
    "\tspeed_sheets.append(speed_sheet)\n",
    "\n",
    "rows_total=[]\n",
    "total_dfs=[]\n",
    "with pd.ExcelWriter(f'{folder}.xlsx') as writer: \n",
    "\tfor df,speed  in zip(speed_sheets,speeds): \n",
    "\t\trows_total=[]\n",
    "\n",
    "\t\tfor name in df['Name'].unique():\n",
    "\t\t\tfor force in df['Force'].unique():\n",
    "\t\t\t\tprint(f\"----------{name}\\t{force}------------\")\n",
    "\t\t\t\tdf2=df[(df['Name']==name) & (df['Force']==force)]\n",
    "\t\t\t\tif df2.empty:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tCoF_total_avg=np.average(df2['CoF_avg'])\n",
    "\t\t\t\tCoF_total_std=np.sqrt(np.sum(df2['CoF_std'].to_numpy()**2))/len(df2['CoF_std'])\n",
    "\t\t\t\tprint(f\"std: {np.average(df2['CoF_std'])}\\t {CoF_total_std}\")\n",
    "\t\t\t\tprint(df2.get(\"Force\").iloc[0],df2.get(\"Percent\").iloc[0])\n",
    "\n",
    "\t\t\t\trow=[name,CoF_total_avg,CoF_total_std,speed,df2.get(\"Force\").iloc[0],df2.get(\"Percent\").iloc[0]]\n",
    "\t\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t\tprint(row)\n",
    "\t\t\t\trows_total.append(row)\n",
    "\t\tdf=pd.DataFrame(rows_total,columns=['Name','CoF_avg','CoF_std','Speed', 'Force','Percent'])\n",
    "\t\ttotal_dfs.append(df)\n",
    "\t\tdf.to_excel(writer, sheet_name=speed, index=False)\n",
    "\t\n",
    "\tcomplete_df=pd.concat(total_dfs)\n",
    "\tcomplete_df.to_excel(writer, sheet_name='Total', index=False)\n",
    "\tcomplete_CoF_df.to_excel(writer, sheet_name='CoF', index=True)\n",
    "\tsg_smoothing.to_excel(writer, sheet_name='Smoothed CoF', index=True)\n",
    "\t\n",
    "\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for column in sg_smoothing.columns:\n",
    "    if '20N' or '10N' in column:\n",
    "        plt.plot(sg_smoothing[column],label=column)\n",
    "        plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_CoF_tests = {'OA_Project_Tests_CoF':['100-TOCN_20N_20mms_Test8', \\\n",
    "                                         '20wt_C20A_10N_20mms_Test6', \\\n",
    "                                         '20wt_C20A_10N_100mms_Test14', \\\n",
    "                                         '20wt_C20A_20N_20mms_Test16new', \\\n",
    "                                         '20wt_C20A_20N_100mms_Test12', \\\n",
    "                                        '20wt_C20A2wtOA_10N_20mms_Test8', \\\n",
    "                                        '20wt_C20A2wtOA_10N_100mms_Test4', \\\n",
    "                                        '20wt_C20A2wtOA_20N_20mms_Test6', \\\n",
    "                                        '20wt_C20A2wtOA_20N_100mms_Test17new', \\\n",
    "                                        '100-TOCN_10N_100mms_Test12', \\\n",
    "                                        '100-TOCN_10N_20mms_Test6', \\\n",
    "                                        '100-TOCN_20N_100mms_Test14'], \\\n",
    "                                        \n",
    "                 'PAO_IL_ZDDP_CoF': ['0_OA0_20N_100mms_test13', \\\n",
    "                                     '0_OA0_20N_20mms_test1', \\\n",
    "                                     '1-ZADP_20N_100mms_Test5', \\\n",
    "                                     '1-ZADP_20N_20mms_Test3', \\\n",
    "                                     '1_IL_20N_100mms_Test5', \\\n",
    "                                     '1_IL_20N_20mms_Test4']}                      \n",
    "\n",
    "pattern = r'(_test|_Test).*'\n",
    "unique_names = {}\n",
    "\n",
    "for column in sg_smoothing.columns:\n",
    "    if '10mms' in column:\n",
    "         continue\n",
    "    if '20N' or '10N' in column:\n",
    "    # if '20N' in column:\n",
    "\n",
    "        # Apply the regex pattern to get the unique name\n",
    "        unique_name = re.sub(pattern, '', column)\n",
    "        # Check if the unique name is already a key in the dictionary\n",
    "        if unique_name in unique_names:\n",
    "            # Append the original column name to the list associated with the unique name\n",
    "            unique_names[unique_name].append(column)\n",
    "        else:\n",
    "                # Create a new entry with the unique name as the key and a list containing the original column name\n",
    "                unique_names[unique_name] = [column]\n",
    "\n",
    "os.makedirs(f'{folder}_Images', exist_ok=True)\n",
    "\n",
    "for (key, value) in unique_names.items():\n",
    "    for spec_val in value:\n",
    "        plt.plot(sg_smoothing[spec_val],label=spec_val)\n",
    "    # plt.title(key)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(f'{folder}_Images', f'{key}.png'))\n",
    "    plt.show()    \n",
    "    # print(key, unique_names[key])\n",
    "\n",
    "# for column in sg_smoothing.columns:\n",
    "#     if '20N' in column:\n",
    "#         if re.sub(pattern, '', column) in unique_names:\n",
    "            \n",
    "#             plt.plot(sg_smoothing[column],label=column)\n",
    "#             plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter(f'{folder}.xlsx') as writer:\n",
    "    # print(sg_smoothing.head())\n",
    "print(avg_CoF_tests[folder], f'\\n Length: {len(avg_CoF_tests[folder])}')\n",
    "count =0\n",
    "good_test_in_folder_list = []\n",
    "for ii in range(len( sg_smoothing.columns)):\n",
    "    for jj in range(len(avg_CoF_tests[folder])):\n",
    "        # print(  avg_CoF_tests[folder][jj]==sg_smoothing.columns[ii])\n",
    "        if  avg_CoF_tests[folder][jj]==sg_smoothing.columns[ii]:\n",
    "            count+=1\n",
    "            print(avg_CoF_tests[folder][jj])\n",
    "            good_test_in_folder_list.append(avg_CoF_tests[folder][jj])\n",
    "print(count)\n",
    "\n",
    "good_test_df = sg_smoothing.loc[:, good_test_in_folder_list]\n",
    "\n",
    "# for good_test in avg_CoF_tests[folder]:\n",
    "#     good_test_df = pd.concat([good_test_df, sg_smoothing[good_test]], ignore_index=True)\n",
    "print(good_test_df)\n",
    "\n",
    "with pd.ExcelWriter(f'{folder}.xlsx', engine='openpyxl', mode='a') as writer: \n",
    "    good_test_df.to_excel(writer, sheet_name='Good_Tests', index=False)\n",
    "    # good_test_df.to_excel(writer, sheet_name='Good Tests', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This block of code will reorganize the \"total\" sheet into a friction table based on the user input which will \\n include percent reduction for ease of integration into origin.')\n",
    "\n",
    "def input_table_title(): # recursive function to get the table title from the user\n",
    "    table_title = input('Would you like to create a friction table based on force or speed? (only type f for force or s for speed): ')\n",
    "    if table_title != 'f' and table_title != 's':\n",
    "        print('Invalid input. Please enter f or s')\n",
    "        input_table_title()\n",
    "    else:\n",
    "        return table_title\n",
    "    \n",
    "def input_include_percent(): # recursive function to get the user input for including the percentages in the friction table\n",
    "    include_percent = input('Would you like to include the percentages in the names in the friction table? (y/n): ')\n",
    "    if include_percent != 'y' and include_percent != 'n':\n",
    "        print('Invalid input. Please enter y or n')\n",
    "        input_include_percent()\n",
    "    else:\n",
    "        return include_percent\n",
    "\n",
    "table_title = input_table_title()\n",
    "reference_sample = input('Please enter the reference sample for the friction table: (sample that you are measuring the percent reduction with respect to) ')\n",
    "include_percent = input_include_percent()\n",
    "\n",
    "possible_params = {'f': 'Force', 's': 'Speed'} # dictionary storing the possible parameters in total sheet and their units\n",
    "dataframe_dict = {} # dictionary to store the dataframes for each unique table title\n",
    "other_unique_params = {} # dictionary to store the unique parameter values for the other parameter(s) in the possible params dictionary\n",
    "\n",
    "total_dataframe = pd.read_excel(f'{folder}.xlsx', sheet_name='Total')\n",
    "\n",
    "unique_param_titles = total_dataframe[possible_params[table_title]].unique() # unique parameter table title values stored as a list\n",
    "\n",
    "for (key, value) in possible_params.items(): # loop through the possible params dictionary\n",
    "    if key == table_title: # ignore the table title sample\n",
    "        continue\n",
    "    else:\n",
    "        other_unique_params[value] = total_dataframe[value].unique() # store the unique parameter values for the other parameter(s) in the other unique params dictionary\n",
    "\n",
    "for param in unique_param_titles:\n",
    "    param_df = total_dataframe[total_dataframe[possible_params[table_title]] == param]\n",
    "    param_df = param_df.drop(columns=[possible_params[table_title]])\n",
    "    final_df = pd.DataFrame()\n",
    "    percent_reduction_df = pd.DataFrame()\n",
    "    for other_param in other_unique_params: # entering the other unique params dictionary using the key value\n",
    "        for param2 in other_unique_params[other_param]: # for loop getting all unique params for all non table title parameters\n",
    "            temp_df = param_df[param_df[other_param] == param2]\n",
    "            temp_df = temp_df.drop(columns=[other_param])\n",
    "            reference_value = temp_df[temp_df['Name'] == reference_sample]['CoF_avg'].values[0]\n",
    "            percent_reduction_df = temp_df['CoF_avg'].apply(lambda x: 'REF' if x == reference_value else ((reference_value - x) / reference_value) * 100)\n",
    "\n",
    "            temp_df = temp_df.rename(columns={'CoF_avg': f'{param2}', 'CoF_std': f'{param2} STDEV'})\n",
    "            temp_df.insert(2, 'Percent Reduction', percent_reduction_df)\n",
    "            if final_df.empty:\n",
    "                final_df = temp_df\n",
    "            else:\n",
    "                final_df = pd.merge(final_df, temp_df, how='left', on='Name')\n",
    "    dataframe_dict[f'{param} Table'] = final_df\n",
    "\n",
    "for (key, value) in dataframe_dict.items():\n",
    "    print(f'{key}\\n{value.to_string()}\\n\\n')\n",
    "\n",
    "# df['% Reduction 10N'] = df['10N'].apply(lambda x: 'REF' if x == reference_value else ((reference_value - x) / reference_value) * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
